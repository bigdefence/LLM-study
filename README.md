# 프로젝트 개요  
이 프로젝트는 PyTorch를 활용하여 Transformer 기반 **언어 모델(디코더 모델)**을 구축하고 학습하는 예제입니다. 두 가지 코드 파일을 제공하며, 각각 LLaMA 스타일 모델과 GPT 스타일 모델의 학습을 다룹니다.  
- **`llama_base_train.ipynb`**: 한국어 웹 텍스트 데이터로 **LLaMA 기반 Transformer 디코더 모델**을 학습하는 Jupyter 노트북입니다. Hugging Face의 데이터셋과 사전 학습된 토크나이저를 사용하여 모델을 훈련하며, 학습 후 간단한 챗봇 형태로 결과를 테스트할 수 있습니다.  
- **`decoder_train.py`**: 주어진 입력 텍스트 파일로 **GPT-2 유사 디코더 모델**을 학습하는 독립 실행형 Python 스크립트입니다. GPT-2 토크나이저(`tiktoken`)를 이용해 데이터를 전처리하고 작은 Transformer 모델을 정의하여 텍스트 생성 모델 학습 과정을 보여줍니다.  

이 예제를 통해 대용량 언어 모델의 **토크나이징**, **모델 구성**, **학습 루프 구현**, **모델 저장 및 텍스트 생성** 등의 과정을 배울 수 있습니다.

## 설치 방법  
프로젝트 코드를 실행하기 위해서는 아래 환경과 라이브러리가 필요합니다:  
- **Python 3.8** 이상  
- **PyTorch** (CUDA 지원 가능하면 GPU 사용 권장)  
- **Hugging Face Transformers** 및 **Datasets** 라이브러리 (노트북에서 데이터셋 로드와 토크나이저 사용을 위해 필요)  
- **tiktoken** (GPT-2 토크나이저 사용을 위해 필요)  
- (선택 사항) **Jupyter Notebook** 또는 Jupyter 호환 환경 (노트북 파일 실행용)  

필요한 패키지는 `pip`으로 설치할 수 있습니다. 예를 들어:  

```bash
pip install torch transformers datasets tiktoken
```  

노트북(`.ipynb`)을 실행하려면 Jupyter 환경을 설치하거나 Google Colab을 사용할 수 있습니다. PyTorch는 사용 중인 **CUDA 버전에 맞게** 설치해야 합니다 (자세한 내용은 [PyTorch 공식 사이트](https://pytorch.org/)를 참고하세요).

## 사용 방법  

### 1. Jupyter 노트북 (`llama_base_train.ipynb`) 실행  
1. Jupyter Notebook 또는 Colab에서 `llama_base_train.ipynb` 파일을 엽니다.  
2. 순서대로 모든 셀을 실행합니다. 첫 번째 셀들은 데이터셋 로드 및 전처리를 수행합니다. Hugging Face Hub에서 한국어 텍스트 데이터셋을 다운로드하고 텍스트를 정제한 후, 사전 학습된 토크나이저로 토큰화하여 학습용 데이터를 준비합니다.  
3. 이후 셀에서는 모델 클래스들을 정의하고 `train_model()` 함수를 실행하여 모델을 학습합니다. 기본 설정으로 한 epoch 동안 학습하며, 진행 상황(loss)이 일정 간격으로 출력됩니다. (학습 데이터를 늘리거나 epoch 수를 조정하려면 코드 내 관련 변수를 수정합니다.)  
4. 학습이 완료되면 모델 가중치가 저장되고(`model_1.pt` 등), 노트북 마지막 부분에서 `run_chatbot(model)`을 호출하여 **인터랙티브 챗봇**을 시작할 수 있습니다. 터미널/노트북 입력 창에 질문을 입력하면 모델이 생성한 답변을 출력합니다 (`'exit'`를 입력하면 종료).  

### 2. 파이썬 스크립트 (`decoder_train.py`) 실행  
1. 학습에 사용할 입력 텍스트 파일을 준비합니다. 기본 파일명은 `input.txt`이며, 동일한 디렉토리에 위치해야 합니다. (예: 원하는 텍스트 데이터 또는 말뭉치를 `input.txt`로 저장)  
2. 터미널에서 스크립트를 실행합니다:  

   ```bash
   python decoder_train.py
   ```  

3. 스크립트가 실행되면, 먼저 `input.txt` 내용을 불러와 전처리한 후(`cleaned_input.txt`로 저장), **GPT-2 토크나이저**를 사용해 텍스트를 토큰 시퀀스로 변환합니다. 그런 다음 데이터셋을 생성하고 모델 학습을 시작합니다.  
4. 학습은 기본 설정으로 100 epoch 동안 진행되며, 각 epoch마다 평균 손실값(loss)을 출력합니다. 학습 과정에서 모델 가중치는 매 epoch 종료 시 `model_001.pth`, `model_002.pth` ... 형식으로 저장됩니다.  
5. 학습 완료 후에는 저장된 모델 가중치를 불러와 **텍스트 생성**에 활용할 수 있습니다. 예를 들어, 저장된 `.pth` 파일을 로드한 뒤 모델을 `eval()` 모드로 전환하고 처음 몇 개의 토큰을 주어 **다음 토큰들을 예측**하도록 함으로써 새로운 텍스트를 생성할 수 있습니다 (이 기능은 코드에 직접 구현되어 있지 않으며, 사용자가 필요에 따라 추가해야 합니다).  

## 코드 설명  

### `llama_base_train.ipynb`  
`llama_base_train.ipynb` 노트북은 한국어 **웹 텍스트 데이터**를 사용하여 LLaMA 스타일의 Transformer 디코더 모델을 학습합니다. 주요 구성 요소는 다음과 같습니다:  

- **데이터 로드 및 전처리**: Hugging Face `datasets` 라이브러리를 통해 공개된 한국어 말뭉치(`100suping/korean_unlabeled_web_text` 데이터셋의 `train` 분할)를 불러옵니다. 최대 10,000개의 샘플만 사용하도록 설정되어 있으며(`max_samples=10000`), 불필요한 문자 제거 및 공백/개행 정리를 통해 **텍스트 정제**를 수행합니다. 정제된 텍스트는 `'korean_webtext_cleaned.txt'` 파일로 저장됩니다.  
- **토크나이저 설정**: Hugging Face `AutoTokenizer`를 사용하여 사전 학습된 한국어 토크나이저를 로드합니다 (`'LGAI-EXAONE-3.5-7.8B-Instruct'` 토크나이저). 이 토크나이저로 정제된 텍스트를 **토큰화**하고, 토큰 사전 크기(`VOCAB_SIZE`)를 가져옵니다.  
- **데이터셋 생성**: `MyDataset` 클래스를 정의하여 대용량 텍스트를 학습에 사용할 **입력/타겟 시퀀스**로 변환합니다. `MyDataset`은 전체 텍스트 토큰 시퀀스를 주어진 `max_len`(예: 2048 토큰) 길이로 슬라이딩하며 잘라서 입력 시퀀스를 만들고, 동일한 크기의 다음 토큰 시퀀스를 타겟으로 생성합니다. `stride`(예: 128)만큼 이동하며 데이터 중복을 통해 더 많은 학습 샘플을 확보합니다. 이 데이터셋을 `DataLoader`로 감싸 배치(batch) 단위로 모델에 공급합니다 (예: `batch_size=8`).  
- **모델 아키텍처 구현**: 노트북에서는 LLaMA 모델과 유사한 **Transformer 디코더**를 PyTorch로 직접 구현합니다. 주요 클래스와 특징은 아래와 같습니다:  
  - `RotaryEmbedding`: 입력 벡터에 로터리 포지셔널 임베딩(ROPE)을 적용하기 위한 모듈입니다. 사인(sin)과 코사인(cos) 테이블을 미리 계산하여 저장한 뒤, 각 시퀀스 위치의 쿼리/키 벡터에 해당 위치별 회전 변환을 적용합니다. (LLaMA 모델에서 사용된 기법으로, 각 어텐션 헤드의 일부 차원에 위치 정보를 주입)  
  - `GQA` (Grouped Query Attention): 다중 헤드 자기어텐션을 구현한 클래스입니다. 쿼리, 키, 밸류에 대한 선형 변환(`q_proj`, `k_proj`, `v_proj`)을 수행하고, **캐주얼 마스크**(미래 토큰 차단)를 적용하여 스케일드 닷 프로덕트 어텐션을 계산합니다. `n_query_heads`와 `n_kv_heads`를 분리하여 **키/밸류 헤드 수**를 쿼리 헤드보다 적게 설정하는 최적화 기법을 적용하였습니다 (예: `n_query_heads=12`, `n_kv_heads=4`). 어텐션 출력은 최종 선형 변환(`o_proj`)을 거쳐 원래 차원으로 투영됩니다. 또한 인퍼런스 시 **이전 토큰의 키/밸류 캐시**(`past_kv`)를 받아 이어서 생성할 수 있게 설계되었습니다.  
  - `RMSNorm`: Layer Normalization의 변형인 RMSNorm을 구현한 클래스입니다. 각 층별로 평균 제곱 값의 루트로 정규화하고 학습 가능한 스케일 파라미터를 곱해줍니다. (epsilon=1e-6 사용)  
  - `SwiGLU` 및 `MLP`: SwiGLU는 SiLU(또는 swish) 활성함수와 게이트 방식을 결합한 활성화 함수입니다. `MLP` 클래스는 Transformer 블록 내 피드포워드 신경망으로, 입력 임베딩 차원의 4배 너비를 가진 두 개의 선형층을 SwiGLU 활성함수로 연결합니다. (예: `emb_dim=1536`일 때 내부 은닉 차원은 6144) 출력에는 드롭아웃(`Dropout(0.1)`)이 적용됩니다.  
  - `TransformerBlock`: 한 개의 Transformer 디코더 블록을 나타냅니다. **자기어텐션 서브층**과 **피드포워드 서브층**으로 구성되며, 각 서브층 전에 RMSNorm을 적용하는 **Pre-Norm 구조**를 사용합니다. 어텐션 출력과 피드포워드 출력은 원본 입력에 **잔차 연결(Residual Connection)**을 통해 더해집니다. (`past_kv`와 `use_cache` 인자를 받아, 생성 시 캐시를 다루도록 지원)  
  - `BigdefenceModel`: 전체 Transformer 모델 클래스입니다. 토큰 임베딩(`nn.Embedding`)과 드롭아웃으로 입력을 처리하고, 다중 `TransformerBlock`을 `nn.ModuleList`로 쌓아 `num_layers`만큼 반복합니다 (기본 12층). 마지막으로 RMSNorm을 거친 후 출력층(`lm_head`)에서 어휘집 크기만큼의 로짓을 산출합니다. 이 모델의 `forward`는 학습 시 전체 시퀀스를 한 번에 처리하고, `use_cache=True`일 경우 각 블록의 `k,v`를 리스트로 모아 다음 생성 단계에 사용할 수 있도록 합니다.  
- **모델 학습 루프**: `train_model()` 함수 내에 모델 학습 절차가 구현되어 있습니다. 주요 내용:  
  - 준비된 데이터셋을 배치로 불러오면서, **AdamW 옵티마이저**(learning rate=1e-4)와 **CosineAnnealingLR** 스케줄러를 설정합니다. (`T_max`을 학습 배치 수의 2배로 두어 cosine 주기가 2 epoch가 되도록 설정)  
  - **혼합 정밀도** 훈련을 위해 `torch.cuda.amp.autocast()`와 `GradScaler()`를 사용합니다. 이를 통해 GPU에서 부동소수점 연산 속도를 높이고 메모리 사용을 줄입니다.  
  - 각 미니배치마다 모델을 `train()` 모드로 실행하여 예측 **로짓(logits)**을 얻고, `nn.CrossEntropyLoss`를 사용해 **다음 토큰 예측 손실**을 계산합니다. (출력 로짓을 `logits.view(-1, vocab_size)`로 전개하고 타겟을 일렬로 펼쳐서 손실 계산)  
  - `scaler`를 통해 `loss.backward()` (역전파) 및 `optimizer.step()` (가중치 갱신)을 수행한 뒤 `scaler.update()`로 스케일 조정을 갱신합니다. 각 스텝 후에 러닝레이트 스케줄러도 한 스텝 진행합니다.  
  - `global_step`마다 (예시에서는 100 스텝마다) 누적된 손실의 평균을 출력하여 진행 상황을 모니터링합니다.  
  - Epoch 종료 시 학습된 모델의 가중치를 `torch.save`를 통해 `model_{epoch}.pt` 형식으로 저장합니다. (노트북 기본 설정은 `EPOCHS=1`로 1 epoch만 실행)  
- **텍스트 생성 및 챗봇**: 학습된 모델을 이용해 텍스트를 생성하거나 대화형으로 사용할 수 있습니다.  
  - `generate_with_cache()` 함수는 **자동회귀 텍스트 생성**을 수행합니다. 초기 입력 시퀀스(`idx`)를 받아 최대 `max_new_tokens`만큼 토큰을 생성합니다. 매 단계 생성된 최신 토큰을 모델에 입력하고, 이전 단계의 `past_kv`를 캐시하여 효율적으로 다음 토큰을 예측합니다. 예측 시 **Top-K 샘플링**(`top_k=40`)과 **온도 조절**(`temperature=0.8`)을 적용하여 생성 결과의 다양성을 조절합니다. (만약 `eos_id`를 지정하면 해당 토큰 생성 시 조기 종료)  
  - `run_chatbot(model)` 함수는 사용자 입력을 받아 모델의 응답을 생성하는 간단한 챗봇 루프를 구현합니다. 콘솔에서 프롬프트를 입력받으면 토크나이저로 토큰화하여 모델에 입력하고, `generate_with_cache`를 사용해 응답 토큰 시퀀스를 생성합니다. 생성된 토큰 시퀀스를 다시 디코딩하여 텍스트 응답을 출력합니다. `'exit'`이라는 입력이 들어올 때까지 루프를 지속하여 대화를 나눌 수 있습니다.  

### `decoder_train.py`  
`decoder_train.py` 스크립트는 단일 파일로 self-contained 되어 있으며, GPT 모델과 유사한 작은 Transformer 디코더를 구현하여 **주어진 텍스트 파일로부터 언어 모델을 학습**합니다. 주요 기능은 다음과 같습니다:

- **텍스트 전처리**: 스크립트 실행 시 가장 먼저 `input.txt` 파일을 읽어들입니다. `clean_text()` 함수를 통해 텍스트 내 줄바꿈 문자를 공백으로 치환하고 연속된 공백을 하나로 축소하여 정리합니다. 정제된 결과는 `cleaned_input.txt` 파일로 저장되어 이후 단계에서 사용됩니다. (특수 문자 제거 등의 추가 정제는 하지 않으나, 필요하면 이 함수를 수정하여 구현할 수 있습니다.)  
- **토큰화 및 데이터셋 구성**: **GPT-2 토크나이저**를 제공하는 `tiktoken` 라이브러리를 사용합니다 (`tiktoken.get_encoding('gpt2')`). 정제된 텍스트 전체를 GPT-2 BPE(Byte Pair Encoding) 방식으로 인코딩하여 정수 토큰들의 리스트를 얻습니다. 그런 다음 `MyDataset` 클래스를 활용해 이 토큰 리스트를 학습용 **입력/타겟 시퀀스** 집합으로 변환합니다.  
  - `MyDataset.__init__`: 토큰 리스트를 `max_length` 길이(예시 코드에서는 32 토큰)로 잘라 입력 시퀀스를 만들고, 한 토큰 뒤 shifted된 시퀀스를 타겟으로 설정합니다. `stride` 간격(예시에서는 4)으로 슬라이딩하여 데이터 포인트를 생성하므로, 인접 샘플이 일부 중복된 컨텍스트를 가집니다. 이렇게 생성된 `(input_ids, target_ids)` 쌍들을 리스트에 저장합니다.  
  - 이 데이터셋을 `DataLoader`로 감싸 배치 크기 128로 섞어서(`shuffle=True`) 불러옵니다. (`drop_last=True`로 마지막 불완전 배치는 버립니다.) 스크립트 실행 시 **전체 토큰 개수**가 프린트되어 데이터 규모를 확인할 수 있습니다.  
- **모델 하이퍼파라미터 설정**: 스크립트 상단에 GPT 모델에 필요한 상수들이 정의되어 있습니다.  
  - `VOCAB_SIZE`: 토크나이저의 어휘집 크기 (GPT-2의 경우 50257).  
  - `CONTEXT_LENGTH`: 모델이 사용할 최대 컨텍스트 길이 (기본 128로 정의됨). 이는 위치 임베딩 및 어텐션 마스크 크기에 사용됩니다.  
  - `EMB_DIM`: 임베딩 차원 크기 (예: 768).  
  - `NUM_HEADS`: 어텐션 헤드 개수 (예: 12). 헤드당 차원은 `EMB_DIM/NUM_HEADS`로 계산됩니다 (assert로 나누어떨어짐을 확인).  
  - `NUM_LAYERS`: Transformer 블록 개수 (예: 12).  
  - `DROP_RATE`: 드롭아웃 비율 (예: 0.1).  
  - `QKV_BIAS`: Query/Key/Value 선형층에 바이어스를 사용할지 여부 (기본 False, GPT-2와 동일하게 QKV에 bias 미사용).  
- **모델 구성 요소 구현**: GPT-2 Small과 유사한 구조의 **Transformer 디코더 모델**을 직접 구현합니다. 주요 클래스는 아래와 같습니다:  
  - `MultiHeadAttention`: 다중 헤드 **자기어텐션** 레이어입니다. 입력 `x`의 차원은 `[batch, seq_len, EMB_DIM]`이며, 내부에서 Query, Key, Value를 각각 선형 변환(`Linear(d_in, d_out)`)하여 `[batch, seq_len, d_out]` 형태로 얻습니다 (`d_out = EMB_DIM`). 그런 다음 `NUM_HEADS`로 분할해 `[batch, NUM_HEADS, seq_len, head_dim]` 형태로 변환합니다. 어텐션 스코어는 `queries @ keys^T`로 계산되며, 미리 `register_buffer`로 정의된 상三각 **마스크**(`mask`)를 이용해 미래 위치에 해당하는 스코어에 `-inf`를 채워넣어 **캐주얼 어텐션**을 적용합니다. 이후 스코어를 헤드 차원 크기의 제곱근으로 나누어 스케일링하고 softmax를 취한 뒤, **드롭아웃**을 적용합니다. 얻어진 어텐션 가중치를 `values`에 곱하여 문맥 벡터(context vector)를 구하고, 차원을 원래대로 합친 다음 최종 출력 선형층(`out_proj`)으로 투영합니다. 이 반환값이 어텐션 서브층의 출력으로서 residual 연결을 통해 입력에 더해지게 됩니다.  
  - `LayerNorm`: PyTorch 기본 LayerNorm을 쓰지 않고 직접 구현한 **층 정규화** 클래스입니다. 입력 벡터의 마지막 차원에 대해 평균과 분산을 구해 정규화하고, 학습 가능한 `scale`(초기값 1)과 `shift`(초기값 0) 파라미터를 적용합니다. (`epsilon=1e-5`로 수치 안정성 확보)  
  - `GELU`: Gaussian Error Linear Unit 활성화 함수의 구현체입니다. (`torch.nn.functional.gelu`와 동일한 동작을 수식으로 명시)  
  - `FeedForward`: Transformer의 피드포워드 신경망 부분입니다. 두 개의 선형층으로 구성되며 (`EMB_DIM -> 4*EMB_DIM -> EMB_DIM`), 중간에 `GELU` 활성화 함수를 적용합니다. (`nn.Sequential`로 구성)  
  - `TransformerBlock`: 하나의 Transformer 디코더 블록을 정의한 클래스입니다. 내부에 **멀티헤드 어텐션(`attn`) 서브층**과 **피드포워드(`ff`) 서브층**을 포함하고, 두 서브층 각각에 대해 LayerNorm (사전 정규화)과 잔차 연결을 적용합니다. 구체적으로, 입력 `x`에 먼저 `norm1`을 적용한 후 어텐션을 수행하고 드롭아웃을 거쳐 원본 입력에 더합니다. 이 결과를 다시 `norm2`로 정규화한 뒤 피드포워드 신경망을 통과시키고 드롭아웃 후 이전 출력에 더해 최종 결과를 얻습니다. 이러한 블록을 다수 쌓아 깊은 Transformer를 구성합니다.  
  - `GPTModel`: 전체 GPT 언어 모델 클래스입니다. 토큰 임베딩(`tok_emb`)과 **위치 임베딩**(`pos_emb`) 레이어를 갖추고 있으며, 입력 시퀀스 길이만큼의 위치 인덱스를 생성하여 해당 위치 임베딩을 더합니다. 설정된 개수만큼의 `TransformerBlock`을 `nn.Sequential`로 연결하여 인코딩을 수행하고, 마지막으로 `LayerNorm`을 적용한 뒤 출력층(`out_head`)에서 각 토큰 위치에 대한 다음 토큰 예측 확률 분포(로짓)를 산출합니다. `forward(input_idx)`의 입력 크기는 `[batch, seq_len]` 형태의 토큰 인덱스이며, 반환되는 `logits`의 크기는 `[batch, seq_len, VOCAB_SIZE]`입니다.  
- **모델 학습 루프**: 스크립트 하단부에서는 위에서 정의된 데이터로더와 모델을 사용하여 학습을 수행합니다. 동작 방식은 다음과 같습니다:  
  - 학습을 위한 디바이스(`device`)를 설정하고 (`cuda` 사용 가능 시 GPU, 아니면 CPU), 모델을 해당 디바이스로 이동시킵니다.  
  - **AdamW 옵티마이저**를 초기화합니다 (학습률 `lr=1e-5`, 가중치 감쇠 `weight_decay=0.1`). 별도의 러닝레이트 스케줄러나 정밀도 조정은 사용하지 않습니다 (필요시 코드 수정으로 추가 가능).  
  - 100 epoch 동안 루프를 돌며 학습합니다. 각 epoch에서 `model.train()` 모드로 설정한 후 `train_loader`를 순회합니다.  
    - 배치마다 모델에 입력을 넣고 **예측 logits**를 얻습니다. 그런 다음 `F.cross_entropy` 함수를 사용하여 예측값과 타겟 시퀀스 간의 **교차 엔트로피 손실**을 계산합니다. (`logits.flatten(0,1)`와 `target_batch.flatten()`으로 배치 차원과 시퀀스 차원을 펼쳐 비교)  
    - `optimizer.zero_grad()`로 이전 그래디언트를 초기화하고, `loss.backward()`를 호출하여 **역전파**로 그래디언트를 계산한 뒤 `optimizer.step()`으로 모델 파라미터를 업데이트합니다.  
    - (코드에는 `tokens_seen += input_batch.numel()` 및 `global_step += 1`와 같은 변수가 등장하지만, 이는 학습 진행을 추적하기 위한 것으로 초기화나 활용 부분은 생략되어 있습니다. 필요에 따라 해당 변수를 초기화하고 사용자가 커스텀 로직을 추가할 수 있습니다.)  
  - 각 epoch이 끝나면 누적된 손실로 **평균 손실값**을 계산하여 출력하고, `losses` 리스트에 기록합니다. 또한 `torch.save()`를 통해 모델의 `state_dict()`를 `'model_{epoch:03d}.pth'` 형식으로 저장하여 체크포인트를 남깁니다. 예를 들어, 1 epoch 후에는 `model_001.pth`, 2 epoch 후에는 `model_002.pth`가 생성됩니다.  
  - 학습이 완료된 후에는 필요한 경우 저장된 가중치를 로드하여 모델을 복원할 수 있습니다 (`model.load_state_dict(torch.load('model_100.pth'))`). 복원한 모델을 `model.eval()`로 전환한 뒤, 새로운 텍스트에 대한 토큰 시퀀스를 입력하여 `model()`을 호출함으로써 다음 토큰들을 예측/생성할 수 있습니다. (생성 루프나 상호작용 인터페이스는 포함되어 있지 않으므로 사용자 정의로 구현해야 합니다.)  

## 모델 학습 및 평가  
이 프로젝트의 두 코드 파일 모두 **다음 단어 예측 언어 모델** 학습을 위한 전형적인 절차를 수행합니다. **학습 루프**에서는 모델 출력과 정답 토큰 시퀀스 간 교차 엔트로피 손실을 최소화하도록 파라미터를 업데이트하며, 학습 중 손실값을 출력하여 수렴 정도를 확인할 수 있습니다.  

- **학습 구성**: 기본적으로 단일 GPU 환경에서 실행되도록 구성되어 있습니다. `llama_base_train.ipynb`에서는 혼합 정밀도 훈련과 Cosine Annealing 학습률 스케줄링을 포함하여 효율성과 안정성을 높였으며, `decoder_train.py`는 보다 단순한 설정으로 구현되어 있습니다. 두 경우 모두 **AdamW 옵티마이저**가 사용되고, 배치별로 옵티마이저 스텝을 수행합니다.  
- **모델 저장**: 학습 진행 중 주기적으로 (epoch마다) 모델 가중치를 저장하므로, 중간 결과를 보존하거나 최종 모델을 배포용으로 활용할 수 있습니다. 필요한 경우 특정 epoch의 모델을 불러와 추가 학습을 이어가거나(`torch.load`로 가중치 로드 후 `model.train()` 재개) 추론에 사용할 수 있습니다.  
- **평가 및 사용**: 코드 상에는 별도의 **검증/테스트 단계**나 평가 지표(예: 퍼플렉서티) 계산이 구현되어 있지 않습니다. 모델 성능 평가는 주로 학습 손실 감소 추이를 통해 이루어지며, 학습 후에는 **텍스트 생성 결과**를 관찰함으로써 모델의 언어 생성 능력을 평가합니다. 예를 들어, 노트북에서는 `run_chatbot` 함수를 통해 사용자 질문에 대한 모델의 응답을 직접 확인할 수 있습니다. 사용자는 추가로 별도 검증용 데이터를 준비해 학습된 모델의 퍼플렉서티를 측정하거나, 사람이 읽어서 생성된 텍스트의 품질을 판단하는 방식으로 평가를 진행할 수 있습니다.  
- **추론(Inference)**: 학습을 마친 언어 모델은 주어진 프롬프트(초기 문장)에 이어지는 텍스트를 생성하는 데 사용할 수 있습니다. 노트북의 `generate_with_cache` 예시처럼 토큰을 하나씩 생성하는 **자동완성/생성** 절차를 구현해야 합니다. 생성 과정에서는 **도입된 샘플링 기법**(예: top-k, 온도 조절)을 적절히 활용하여 현실적이고 다양한 결과를 얻을 수 있습니다.  

## 기타 참고 사항  
- **학습 데이터 및 시간**: 제공된 코드는 개념 증명을 위한 작은 데이터셋과 간략한 epoch 설정으로 실행됩니다. 실제로 의미 있는 언어 모델을 얻기 위해서는 더 방대한 말뭉치 데이터와 충분한 학습 시간이 필요합니다. 예를 들어, `llama_base_train.ipynb`에서 `max_samples`나 `EPOCHS` 값을 증가시키고, `decoder_train.py`에서도 더 큰 `input.txt`와 충분한 epoch를 사용하면 모델 성능을 향상시킬 수 있습니다. 단, 학습 데이터가 클 경우 연산 자원(GPU 메모리 등)의 한계를 고려해야 합니다.  
- **토크나이저 교체**: 노트북 예제에서는 `'LGAI-EXAONE-3.5-7.8B-Instruct'`라는 특정 사전 학습 한국어 토크나이저를 사용합니다. 해당 토크나이저에 접근할 수 없거나 다른 언어/도메인에 적용하려는 경우, Hugging Face의 `AutoTokenizer`를 이용해 다른 한국어 토크나이저(예: KoGPT2 토크나이저 등)나 목적에 맞는 토크나이저로 쉽게 교체할 수 있습니다. 마찬가지로 `decoder_train.py`는 기본 GPT-2 BPE 토크나이저를 사용하므로 영어 이외의 언어 텍스트를 학습하려면 해당 언어에 맞는 토크나이저를 사용하도록 수정하는 것이 좋습니다.  
- **모델 구조 변경**: 코드에 하드코딩된 하이퍼파라미터(레이어 수, 헤드 수 등)를 변경함으로써 모델 크기를 조절할 수 있습니다. 예를 들어, 더 큰 모델이나 작은 모델을 시험해 볼 수 있으며, 드롭아웃 비율을 조정하여 **과적합**을 방지하거나 훈련 안정성을 높일 수 있습니다. 또한 `decoder_train.py`의 경우 `CONTEXT_LENGTH`를 128보다 크게 늘려 더 긴 시퀀스를 한 번에 학습하도록 개선할 수 있습니다 (이 경우 `mask` 텐서 크기도 함께 조정해야 합니다).  
- **성능 개선**: 실제 대규모 모델 훈련 시에는 Gradient Accumulation, Mixed Precision, Gradient Clipping, Learning Rate Warmup 등 다양한 기법을 활용해 학습을 안정화하고 속도를 높일 수 있습니다. 본 예시 코드에서는 일부 기법(혼합 정밀도 등)만 도입되어 있으므로, 필요한 경우 PyTorch Lightning이나 Hugging Face Trainer와 같은 고급 프레임워크를 도입하는 것도 고려해볼 수 있습니다.  
- **추가 기능 구현**: 현재 코드는 **텍스트 생성 모델 학습의 기본 요소**에 집중하고 있습니다. 사용자는 이를 기반으로 다양한 기능을 추가할 수 있습니다. 예를 들어, 주어진 모델을 활용하여 샘플 텍스트 생성 결과를 파일로 저장하거나, 생성된 텍스트에 대한 후처리(불필요한 토큰 제거 등)를 수행하는 스크립트를 만들 수 있습니다. 챗봇 기능을 발전시켜 대화 이력을 문맥으로 넣는 등 고도화하거나, 사용자 인터페이스를 개선하여 웹에서 동작하는 챗봇 데모로 확장하는 것도 가능합니다. 모델 평가를 위해 **별도의 검증 데이터셋**을 준비하고 학습 중 주기적으로 검증 손실이나 퍼플렉서티를 출력하도록 코드를 확장하면 모델의 일반화 성능을 모니터링하는 데 도움이 될 것입니다.  

이 README의 내용을 바탕으로 코드를 실행하고 수정하면서, 사용자는 **Transformer 기반 언어 모델의 학습 과정**을 단계별로 이해하고 자신만의 응용을 시도해볼 수 있습니다. 모델 구현과 실험을 통해 얻은 통찰을 바탕으로 향후 더욱 발전된 언어 모델을 만드는 토대를 마련하시길 바랍니다.
